# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Options: "openai" or "vllm"
# - openai: Use OpenAI's API (requires API key and internet)
# - vllm: Use self-hosted vLLM server (requires GPU hardware)
LLM_PROVIDER=openai

# =============================================================================
# OpenAI Configuration (when LLM_PROVIDER=openai)
# =============================================================================
OPENAI_API_KEY=sk-your-api-key-here
# Optional: Custom OpenAI base URL (for Azure OpenAI, etc.)
# OPENAI_BASE_URL=https://api.openai.com/v1

# =============================================================================
# vLLM Configuration (when LLM_PROVIDER=vllm)
# =============================================================================
# URL of your vLLM server
VLLM_API_BASE=http://localhost:8000/v1
# vLLM typically doesn't require authentication
VLLM_API_KEY=EMPTY

# =============================================================================
# Model Configuration
# =============================================================================
# For OpenAI: gpt-4o, gpt-4-turbo, gpt-3.5-turbo, etc.
# For vLLM: meta-llama/Llama-3.1-8B-Instruct, Qwen/Qwen2.5-7B-Instruct, etc.
MODEL_NAME=hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4
MAX_TOKENS=4000
TEMPERATURE=0.7

# =============================================================================
# Miner Configuration
# =============================================================================
MINER_NAME=sample-miner
MINER_PORT=8001
HOST=0.0.0.0

# Miner API Key (required in X-API-Key header for all requests)
MINER_API_KEY=your-secret-miner-api-key-here

# =============================================================================
# API Settings
# =============================================================================
DEBUG=false
LOG_LEVEL=info
